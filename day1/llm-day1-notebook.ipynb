{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD LLM Bootcamp Day 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisite: Run the following commands in a terminal window to create a conda environment.\n",
    "\n",
    "<pre>\n",
    "- conda create --name llm-bootcamp -c https://repo.anaconda.com/pkgs/snowflake python=3.9\n",
    "- conda activate llm-bootcamp\n",
    "- conda install -c https://repo.anaconda.com/pkgs/snowflake snowflake-snowpark-python pandas notebook\n",
    "<pre/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake-ml-python==1.0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.34.0 tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.ml.model.models import llm\n",
    "from snowflake.ml.registry import model_registry\n",
    "from snowflake.ml.model import deploy_platforms\n",
    "from snowflake.snowpark import VERSION\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Secure Connection\n",
    "\n",
    "*NOTE: Update [connection.json](connection.json) and set your password, Hugging Face token, and replace '####' with your user number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('select current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Llama 2 from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = llm.LLMOptions(\n",
    "    token=connection_parameters['huggingface_token'],\n",
    "    max_batch_size=100,\n",
    ")\n",
    "llama_model = llm.LLM(\n",
    "    model_id_or_path=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    options=options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register, Log and Deploy Llama 2 into Snowpark Container Services \n",
    "\n",
    "*NOTE: Logging and deploying the same model are one time operations. Once the model is logged and deployed, use ModeReference to get the reference to the model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME    = \"LLAMA2_7b_CHAT\"\n",
    "MODEL_VERSION = \"NewBaseV2.0\"\n",
    "MODEL_REGISTRY_DB = connection_parameters['database']\n",
    "MODEL_REGISTRY_SCHEMA = connection_parameters['schema']\n",
    "COMPUTE_POOL = connection_parameters['compute_pool']\n",
    "\n",
    "registry = model_registry.ModelRegistry(\n",
    "    session=session, \n",
    "    database_name=MODEL_REGISTRY_DB, \n",
    "    schema_name=MODEL_REGISTRY_SCHEMA, \n",
    "    create_if_not_exists=True)\n",
    "\n",
    "llama_model_ref = registry.log_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    model_version=MODEL_VERSION,\n",
    "    model=llama_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Deploying model for the first time can take ~25-30mins*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Optionally enable INFO log level\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "llama_model_ref.deploy(\n",
    "    deployment_name=\"llama_predict\", \n",
    "    platform=deploy_platforms.TargetPlatform.SNOWPARK_CONTAINER_SERVICES,\n",
    "    permanent=True, \n",
    "    options={\"compute_pool\": COMPUTE_POOL, \"num_gpus\": 1})\n",
    "\n",
    "llama_model_ref = model_registry.ModelReference(registry=registry,model_name=MODEL_NAME,model_version=MODEL_VERSION)\n",
    "llama_model_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from JSON into Snowflake\n",
    "\n",
    "*NOTE: Reading data in JSON and storing it in a Snowflake table are one time operations. Once the data is loaded, use Snowpark to load the data from the existing table.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"data/frosty_transcripts.json\",lines=True)\n",
    "sf_df = session.write_pandas(df,'frosty_transcripts',auto_create_table=True,quote_identifiers=False,overwrite=True)\n",
    "sf_df.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Prompt Engineering Example\n",
    "\n",
    "For every transcript, define summarization instruction for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_prompt = \\\n",
    "\"\"\"\n",
    "[INST] Summarize this transcript in less than 200 words: \n",
    "\"\"\"\n",
    "end_prompt = \" [/INST]\"\n",
    "\n",
    "df_inputs = sf_df.with_column('\"input\"',F.concat_ws(F.lit(\" \"),F.lit(begin_prompt),F.col('transcript'),F.lit(end_prompt))).select('\"input\"')\n",
    "df_inputs.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference using Simple Prompt\n",
    "\n",
    "Pass the summariation instruction to the LLM and examine results of 10 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict_results = llama_model_ref.predict(deployment_name=\"llama_predict\",data=df_inputs)\n",
    "df_predict_results.select('\"input\"','\"generated_text\"').limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Prompt Engineering and Inference Example\n",
    "\n",
    "For every transcript, define more specific instruction for the LLM\n",
    "\n",
    "*NOTE: In the results, notice that the output is not consistent across all transcripts. The base model failed to follow the instructions in many of the cases as seen below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = session.table('frosty_transcripts')\n",
    "\n",
    "begin_prompt = \\\n",
    "\"\"\"\n",
    "[INST] Extract location and list of toys in JSON format: \n",
    "\"\"\"\n",
    "end_prompt = \" [/INST]\"\n",
    "\n",
    "df_inputs = sf_df.with_column('\"input\"',F.concat_ws(F.lit(\" \"),F.lit(begin_prompt),F.col('transcript'),F.lit(end_prompt))).select('\"input\"')\n",
    "df_predict_results = llama_model_ref.predict(deployment_name=\"llama_predict\",data=df_inputs)\n",
    "df_predict_results.limit(10).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD LLM Bootcamp Day 2 Preparation\n",
    "\n",
    "Follow the instructions below to prepare your environment for BUILD LLM Bootcamp Day 2. \n",
    "\n",
    "*NOTE:* These operations can take about ~45-60mins depending on your wireless connection.\n",
    "\n",
    "1) Open terminal window and browse to the folder where you have cloned the repository\n",
    "\n",
    "2) Change folder to *day2*\n",
    "\n",
    "3) Run command *`docker build --platform linux/amd64 -t llm-bootcamp .`*\n",
    "\n",
    "4) Once that image is built locally, run the following commands to push the image to Snowflake Registry\n",
    "\n",
    "    1) Replace ***your-account-name*** with your account name and ***your-db-name*** with the name of your database ***in lowercase*** and then run the following command\n",
    "\n",
    "        `docker tag llm-bootcamp:latest sfsenorthamerica-your-account-name.registry.snowflakecomputing.com/your-db-name/schema_llm/image_repo/llm-bootcamp:latest`\n",
    "\n",
    "    2) Replace ***your-account-name*** with your account name and run the following command to login using your LLM Bootcamp Snowflake account username and password\n",
    "\n",
    "        `docker login sfsenorthamerica-your-account-name.registry.snowflakecomputing.com`\n",
    "        \n",
    "    3) Replace ***your-account-name*** with your account name and ***your-db-name*** with the name of your database ***in lowercase*** and then run the following command\n",
    "    \n",
    "        `docker push sfsenorthamerica-your-account-name.registry.snowflakecomputing.com/your-db-name/schema_llm/image_repo/llm-bootcamp:latest`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
